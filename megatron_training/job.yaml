# Anyscale Job configuration for Megatron-Bridge training

name: ray-train-megatron-bridge

# Build a custom image using the local Dockerfile
containerfile: ./Dockerfile  
cloud: 


# When empty, Anyscale will auto-select the instance types. You can also specify
# minimum and maximum resources.
compute_config:  

working_dir: .

env_vars:
  RAY_TRAIN_V2_ENABLED: "1"
  CUDA_DEVICE_MAX_CONNECTIONS: "1"  # Required for sequence parallelism
  MEGATRON_BRIDGE_ROOT: "/app/Megatron-Bridge"
  PYTHONPATH: "/app/Megatron-Bridge/src:/app/Megatron-Bridge/3rdparty/Megatron-LM"
  NCCL_DEBUG: "WARN"
  PYTHONUNBUFFERED: "1"

# Simplified entrypoint - TP=2, PP=2, batch sizes are hardcoded in script
entrypoint: |
  python llm_sft_ray_train_megatron.py \
    --hf_model_path Qwen/Qwen2.5-1.5B \
    --num_workers 8 \
    --train_iters 100 \
    --storage_path /mnt/local_storage/megatron_experiment
